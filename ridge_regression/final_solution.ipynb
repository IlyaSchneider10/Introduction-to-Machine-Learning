{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic, WhiteKernel\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the data and imputes the NA values using two different imputing techniques\n",
    "\n",
    "def data_loading():\n",
    "\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "    test_df_colnames = test_df.columns[1:].to_list()\n",
    "\n",
    "    #drop priceCHF into y_train\n",
    "    y_train = train_df['price_CHF']\n",
    "    train_df = train_df.drop(['price_CHF'],axis=1)\n",
    "\n",
    "    #scale train and test with the same scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #One Hot encoding of seasons\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_seasons = encoder.fit_transform(train_df['season'].values.reshape(-1, 1))\n",
    "    encoded_seasons_test = encoder.transform(test_df['season'].values.reshape(-1, 1))\n",
    "    encoded_seasons_df = pd.DataFrame(encoded_seasons, columns=encoder.get_feature_names_out(['season']))\n",
    "    encoded_seasons_df_test = pd.DataFrame(encoded_seasons_test, columns=encoder.get_feature_names_out(['season']))\n",
    "    train_df = pd.concat([encoded_seasons_df, pd.DataFrame(scaler.fit_transform(train_df.drop('season', axis=1)))], axis=1)\n",
    "    test_df = pd.concat([encoded_seasons_df_test, pd.DataFrame(scaler.transform(test_df.drop('season', axis=1)))], axis=1)\n",
    "\n",
    "    colnames_test = test_df.columns[:4]\n",
    "    colnames_list = colnames_test.to_list()\n",
    "    colnames_list = colnames_list + test_df_colnames\n",
    "\n",
    "    train_df.columns = colnames_list\n",
    "    colnames_list_2 = colnames_list + ['price_CHF']\n",
    "    \n",
    "    #imputing training set\n",
    "    imp = IterativeImputer(max_iter=1000, random_state=0)\n",
    "    imp.fit(train_df)\n",
    "    imp_df = pd.DataFrame(imp.transform(train_df))\n",
    "    imp_df.columns = colnames_list\n",
    "    imp_df_y = pd.concat([imp_df, y_train], axis=1)\n",
    "    imputer = KNNImputer()\n",
    "    imp_df_y = pd.DataFrame(imputer.fit_transform(imp_df_y))\n",
    "    imp_df_y.columns = colnames_list_2\n",
    "    \n",
    "    #imputing test set\n",
    "    test_df.columns = colnames_list\n",
    "    imp_test_df = pd.DataFrame(imp.transform(test_df))\n",
    "    imp_test_df.columns = colnames_list\n",
    "\n",
    "    X_train = imp_df_y.drop(['price_CHF'],axis=1).to_numpy()\n",
    "    y_train = imp_df_y['price_CHF'].to_numpy()\n",
    "    X_test = imp_test_df\n",
    "\n",
    "    assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for picking the best kernel by implementing cross validation from Project 1\n",
    "## Crossvalidation is done to determine the best kernel\n",
    "## Calculate RMSE for each of the 10 runs of crossvalidation and then compute the average, which corresponds to each kernel\n",
    "\n",
    "def calculate_RMSE(y_truth, y_pred):\n",
    "    \n",
    "    RMSE=np.sqrt(np.sum((y_truth-y_pred)**2)/y_truth.shape[0])\n",
    "\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE\n",
    "\n",
    "\n",
    "def average_LR_RMSE(X_train, y_train, kernels, n_folds):\n",
    "\n",
    "    RMSE_mat = np.zeros((n_folds, len(kernels)))        \n",
    "    kf=KFold(n_folds)\n",
    "\n",
    "    for kf_i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        \n",
    "        train_data=X_train[train_index,:]\n",
    "        train_labels=y_train[train_index]\n",
    "        test_data=X_train[test_index,:]\n",
    "        test_labels=y_train[test_index]\n",
    "\n",
    "        for k_i, k in enumerate(kernels):\n",
    "\n",
    "            gpr = GaussianProcessRegressor(kernel=k) #n_restarts_optimizer = 10\n",
    "            gpr.fit(train_data, train_labels)\n",
    "\n",
    "            y_pred=gpr.predict(test_data)\n",
    "            \n",
    "            run_RMSE=calculate_RMSE(test_labels, y_pred)\n",
    "\n",
    "            RMSE_mat[kf_i,k_i]=run_RMSE\n",
    "    \n",
    "    avg_RMSE = np.mean(RMSE_mat, axis=0)\n",
    "    \n",
    "    assert avg_RMSE.shape == (len(kernels),)\n",
    "    return avg_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses cross validation to test for different kernels, selects the best one and based on that does the predictions\n",
    "def modeling_and_prediction(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    This function defines the model, fits training data and then does the prediction with the test data \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with 10 features\n",
    "    y_train: array of floats, training output\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    y_test: array of floats: dim = (100,), predictions on test set\n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: Define the model and fit it using training data. Then, use test data to make predictions \n",
    "    kernels = [DotProduct(), RBF(), Matern(), RationalQuadratic(), RationalQuadratic() + WhiteKernel(noise_level=0.05)]\n",
    "    n_folds = 10\n",
    "\n",
    "    kernel_summary = average_LR_RMSE(X_train, y_train, kernels, n_folds)\n",
    "\n",
    "    best_kernel = kernels[np.argmin(kernel_summary)]\n",
    "\n",
    "    gpr = GaussianProcessRegressor(kernel=best_kernel)\n",
    "    gpr.fit(X_train, y_train)\n",
    "    y_pred = gpr.predict(X_test)\n",
    "\n",
    "    assert y_pred.shape == (100,), \"Invalid data shape\"\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results file successfully generated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but GaussianProcessRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Data loading\n",
    "    X_train, y_train, X_test = data_loading()\n",
    "    # The function retrieving optimal LR parameters\n",
    "    y_pred=modeling_and_prediction(X_train, y_train, X_test)\n",
    "    # Save results in the required format\n",
    "    dt = pd.DataFrame(y_pred) \n",
    "    dt.columns = ['price_CHF']\n",
    "    dt.to_csv('results_final.csv', index=False)\n",
    "    print(\"\\nResults file successfully generated!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
