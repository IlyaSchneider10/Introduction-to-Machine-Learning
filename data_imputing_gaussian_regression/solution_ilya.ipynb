{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic, Product, Sum, ExpSineSquared\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(data):\n",
    "\n",
    "    split = data.groupby(data.loc[:,\"season\"])\n",
    "\n",
    "    imputer = KNNImputer()\n",
    "    imputed_data = []\n",
    "    \n",
    "    groups = [\"spring\", \"summer\", \"autumn\", \"winter\"]\n",
    "    for group in groups:\n",
    "\n",
    "        full_group = split.get_group(group)\n",
    "        season = full_group.loc[:,\"season\"] \n",
    "        group_to_impute = full_group.drop(['season'],axis=1)\n",
    "        imputed_group = imputer.fit_transform(group_to_impute)\n",
    "        imputed_group = pd.DataFrame(imputed_group, columns = group_to_impute.columns, index =  season.index)\n",
    "        output_group = pd.concat([season, imputed_group], axis=1) \n",
    "        imputed_data.append(output_group)\n",
    "\n",
    "            \n",
    "    imputed_data = pd.concat(imputed_data)\n",
    "    imputed_data = imputed_data.sort_index()\n",
    "\n",
    "    return imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing \n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    print(\"Training data:\")\n",
    "    print(\"Shape:\", train_df.shape)\n",
    "    print(train_df.head(2))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test data:\")\n",
    "    print(test_df.shape)\n",
    "    print(test_df.head(2))\n",
    "\n",
    "    # Data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "    imputed_train = impute_data(train_df)\n",
    "    imputed_test = impute_data(test_df)\n",
    "\n",
    "    # Substitute seasons for values: 0 or 1\n",
    "\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_seasons = encoder.fit_transform(imputed_train['season'].values.reshape(-1, 1))\n",
    "    encoded_seasons_test = encoder.transform(imputed_test['season'].values.reshape(-1, 1))\n",
    "    encoded_seasons_df = pd.DataFrame(encoded_seasons, columns=encoder.get_feature_names_out(['season']))\n",
    "    encoded_seasons_df_test = pd.DataFrame(encoded_seasons_test, columns=encoder.get_feature_names_out(['season']))\n",
    "    imputed_train = pd.concat([encoded_seasons_df, imputed_train.drop('season', axis=1)], axis=1)\n",
    "    imputed_test = pd.concat([encoded_seasons_df_test, imputed_test.drop('season', axis=1)], axis=1)\n",
    "\n",
    "    X_train = imputed_train.drop(['price_CHF'],axis=1).to_numpy()\n",
    "    y_train = imputed_train['price_CHF'].to_numpy()\n",
    "    X_test = imputed_test.to_numpy()\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train =  scaler.fit_transform(X_train)\n",
    "    # X_test=  scaler.transform(X_test)\n",
    "\n",
    "    #assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Shape: (900, 11)\n",
      "   season  price_AUS  price_CHF  price_CZE  price_GER  price_ESP  price_FRA   \n",
      "0  spring        NaN   9.644028  -1.686248  -1.748076  -3.666005        NaN  \\\n",
      "1  summer        NaN   7.246061  -2.132377  -2.054363  -3.295697  -4.104759   \n",
      "\n",
      "   price_UK  price_ITA  price_POL  price_SVK  \n",
      "0 -1.822720  -3.931031        NaN  -3.238197  \n",
      "1 -1.826021        NaN        NaN  -3.212894  \n",
      "\n",
      "\n",
      "Test data:\n",
      "(100, 10)\n",
      "   season  price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK   \n",
      "0  spring        NaN   0.472985   0.707957        NaN  -1.136441 -0.596703  \\\n",
      "1  summer  -1.184837   0.358019        NaN  -3.199028  -1.069695       NaN   \n",
      "\n",
      "   price_ITA  price_POL  price_SVK  \n",
      "0        NaN   3.298693   1.921886  \n",
      "1  -1.420091   3.238307        NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test = data_loading() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for picking the best kernel by implementing cross validation\n",
    "\n",
    "# MAY BE USE R SQUARED AS METRIC FOR CROSS VALIDATION INSTEAD OF RMSE?\n",
    "\n",
    "def calculate_RMSE(y_truth, y_pred):\n",
    "    \n",
    "    RMSE=np.sqrt(np.sum((y_truth-y_pred)**2)/y_truth.shape[0])\n",
    "\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE\n",
    "\n",
    "\n",
    "def average_LR_RMSE(X_train, y_train, kernels, n_folds):\n",
    "\n",
    "    RMSE_mat = np.zeros((n_folds, len(kernels)))        \n",
    "    kf=KFold(n_folds)\n",
    "\n",
    "    for kf_i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        \n",
    "        train_data=X_train[train_index,:]\n",
    "        train_labels=y_train[train_index]\n",
    "        test_data=X_train[test_index,:]\n",
    "        test_labels=y_train[test_index]\n",
    "\n",
    "        for k_i, k in enumerate(kernels):\n",
    "\n",
    "            gpr = GaussianProcessRegressor(kernel=k) #n_restarts_optimizer = 10\n",
    "            gpr.fit(train_data, train_labels)\n",
    "\n",
    "            y_pred=gpr.predict(test_data)\n",
    "            \n",
    "            run_RMSE=calculate_RMSE(test_labels, y_pred)\n",
    "\n",
    "            RMSE_mat[kf_i,k_i]=run_RMSE\n",
    "    \n",
    "    avg_RMSE = np.mean(RMSE_mat, axis=0)\n",
    "    \n",
    "    assert avg_RMSE.shape == (len(kernels),)\n",
    "    return avg_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
    "# Change the parameters to fit\n",
    "\n",
    "def modeling_and_prediction(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    This function defines the model, fits training data and then does the prediction with the test data \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with 10 features\n",
    "    y_train: array of floats, training output\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    y_test: array of floats: dim = (100,), predictions on test set\n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: Define the model and fit it using training data. Then, use test data to make predictions \n",
    "    kernels = [DotProduct(), RBF(), Matern(), RationalQuadratic(), Product(DotProduct(),RationalQuadratic()), Sum(RBF(),Matern()), Sum(DotProduct(), RationalQuadratic()), Sum(RBF(),RationalQuadratic()), Sum(Matern(),RationalQuadratic())]\n",
    "    #kernels = [DotProduct(), RBF(), Matern(), RationalQuadratic()]\n",
    "    #kernels = [ExpSineSquared(length_scale = 1.0, periodicity = 4)]\n",
    "\n",
    "    n_folds = 10\n",
    "\n",
    "    kernel_summary = average_LR_RMSE(X_train, y_train, kernels, n_folds)\n",
    "\n",
    "    best_kernel = kernels[np.argmax(kernel_summary)]\n",
    "\n",
    "    gpr = GaussianProcessRegressor(kernel=best_kernel)\n",
    "    gpr.fit(X_train, y_train)\n",
    "    y_pred = gpr.predict(X_test)\n",
    "\n",
    "    assert y_pred.shape == (100,), \"Invalid data shape\"\n",
    "    return y_pred, best_kernel, kernel_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\schni\\OneDrive\\Documents\\Switzerland\\Bottmedical\\.venv\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred, best_kernel, kernel_summary = modeling_and_prediction(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.46818428,  1.79046239, -1.24501772, -0.72095117, -0.90512172,\n",
       "        2.19252579,  0.78368047,  2.04138866,  0.3012183 ,  2.34136217,\n",
       "        2.23466412,  2.97537568,  1.74043398,  3.13598542,  2.66889499,\n",
       "        1.78282577,  1.64670858,  2.48934502,  2.03442861,  1.37016668,\n",
       "        1.74027616,  2.45862436,  3.13167353,  3.00916411,  3.65571873,\n",
       "        4.79455528,  5.70726227,  7.83764706,  8.94572208,  9.21937903,\n",
       "        8.90993227,  7.8793992 ,  7.93313439,  7.45554671,  7.62334532,\n",
       "        7.71400213,  7.52551312,  7.9736322 ,  7.96784803,  7.2759808 ,\n",
       "        7.76364043,  7.897074  ,  7.93129556,  7.78180917,  7.76220976,\n",
       "        8.14667474,  7.7083312 ,  8.14326486,  7.8862497 ,  7.87208075,\n",
       "        7.60126754,  7.73096487,  7.80603012,  8.51799994,  7.78352523,\n",
       "        9.06344245,  8.34138277,  8.29085505,  6.91779943,  6.35964953,\n",
       "        6.94175796,  5.7026033 ,  5.37811966,  5.49091646,  5.20100524,\n",
       "        5.27301013,  4.84302797,  4.73194778,  4.24511547,  5.30338367,\n",
       "        4.39196294,  5.44562929,  4.10963093,  5.66024113,  5.76591736,\n",
       "        6.30478981,  7.52692973,  7.50021169,  8.02619063,  8.2953786 ,\n",
       "        8.32227335,  8.53522985,  7.61565465,  8.13978528,  8.74155247,\n",
       "        8.68205817,  8.74769777,  8.10439817,  7.81209939,  7.41529259,\n",
       "        7.57666804,  8.0231423 ,  8.84137438,  9.15984472,  8.14536701,\n",
       "        7.66854916,  8.3758222 ,  7.90410186,  6.74565488,  6.39889986])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.51333532,  2.86859805, -1.5486578 , -0.33937393, -0.49528063,\n",
       "        3.10390068,  0.57532579,  1.89730729,  0.22689235,  4.19678375,\n",
       "        1.98248462,  2.95558527,  2.30719446,  4.47860594,  2.62200826,\n",
       "        2.33137736,  1.36629058,  2.67343322,  2.38162737,  0.72343158,\n",
       "        2.37624577,  2.10702976,  3.69116628,  3.44987299,  4.3522458 ,\n",
       "        4.91240802,  5.44266864,  7.90020018,  8.93122756,  9.15141288,\n",
       "        8.90437714,  7.92745998,  7.90415607,  7.52401819,  7.72123636,\n",
       "        7.82271409,  7.51512778,  7.92518056,  8.12169506,  7.30911854,\n",
       "        7.92025858,  7.78188048,  8.03377746,  7.89497639,  7.83980518,\n",
       "        8.15226694,  7.691479  ,  8.14456114,  7.85979573,  7.82209812,\n",
       "        7.70540805,  7.77079755,  7.77764972,  8.59331057,  7.85305483,\n",
       "        8.99659893,  8.37325161,  8.15070318,  6.74971205,  6.3311147 ,\n",
       "        6.95966169,  5.80729368,  5.72793613,  5.7699075 ,  5.28276161,\n",
       "        5.29759637,  4.54689967,  4.44553486,  4.55452181,  5.32544083,\n",
       "        4.17442779,  5.62509385,  4.3581646 ,  5.53675265,  5.6727503 ,\n",
       "        6.42795889,  7.64425672,  7.48677164,  8.08141946,  8.21760563,\n",
       "        8.42005332,  8.53042909,  7.61923497,  8.30715243,  8.70255785,\n",
       "        8.64804643,  8.72893501,  8.07328565,  7.82927466,  7.42103065,\n",
       "        7.57992456,  8.01294402,  8.82734673,  9.11126826,  8.1530922 ,\n",
       "        7.60228594,  8.29485319,  7.82373403,  6.97666982,  6.43911357])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
